{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Register path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dir_of_interest = \"/Volumes/SECONDARY/kerja/ugm/virtualenv_maxent_ner/Program_NER/ner_maxent\"\n",
    "sys.path.append(dir_of_interest)\n",
    "\n",
    "nltk.data.path.append('/Volumes/SECONDARY/applications/nltk/nltk_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import maxent as m\n",
    "import func as f\n",
    "import dbmodel as d\n",
    "\n",
    "classify = m.Maxent()\n",
    "func = f.Func()\n",
    "dbmodel = d.DBModel()\n",
    "classifier = func.open_file('/Volumes/SECONDARY/kerja/ugm/virtualenv_maxent_ner/Program_NER/ner_maxent/train.pickle')\n",
    "# data = classifier.show_most_informative_features(48)\n",
    "# print classifier.weights()\n",
    "# print classifier.labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "from ipywidgets import widgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Input Sentence Convert to NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "text = widgets.Text(description=\"Text : \", width=50)\n",
    "display(text)\n",
    "\n",
    "# 3 warga situbondo meninggal karena dbd\n",
    "# air tergenang digunakan sebagai sarang nyamuk dbd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def handle_submit(sender):\n",
    "    maxent = maximum_entropy(text.value)\n",
    "    print maxent\n",
    "    str_match = combination_string_matching(maxent)\n",
    "    print \"\\n\\n==================================== MaxEnt ==========================================\"\n",
    "    print maxent[\"text_tweet\"]\n",
    "    print \"++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\\n\\n\"\n",
    "    print \"================================ Combination Str Match ===============================\"\n",
    "    print str_match\n",
    "    print \"++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\\n\\n\"\n",
    "     \n",
    "def maximum_entropy(sentence):\n",
    "    return classify.training_ner(sentence.encode(\"utf8\"), classifier)\n",
    "\n",
    "def combination_string_matching(maxent):\n",
    "    sentence_ne = maxent[\"text_tweet\"]\n",
    "    print maxent[\"entity\"]\n",
    "    if \"LOC\" in maxent[\"entity\"]:\n",
    "        entity_location = maxent[\"entity\"][\"LOC\"]\n",
    "        entity_position = maxent[\"entity_position\"]\n",
    "\n",
    "        db_location = \"indo_db\"\n",
    "        location_collection = \"location\"\n",
    "        temp_location = dbmodel.is_candidate_loc(db_location, location_collection, entity_position, entity_location)\n",
    "        loc_clear = dbmodel.is_real_loc(db_location, location_collection, temp_location)\n",
    "        sentence_ne = dbmodel.ner_replace_loc(maxent[\"text_tweet\"], loc_clear)\n",
    "        \n",
    "    if \"CON\" in maxent[\"entity\"]:\n",
    "        if \"sakit\" in maxent[\"entity\"][\"CON\"]:\n",
    "            sentence_ne = dbmodel.validation_CON(sentence_ne, \"sakit\")\n",
    "            print sentence_ne\n",
    "        \n",
    "    return sentence_ne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "text.on_submit(handle_submit)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "widgets": {
   "state": {
    "42b8613c44824e40b6d5c9533abe9d34": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
